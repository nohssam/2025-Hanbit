{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7bb77c-dccc-4fc5-b64d-2fb686c94039",
   "metadata": {},
   "source": [
    "## 정형 데이터와 비정형 데이터\n",
    "> - 정형 데이터 : **행(Row)**과 열(Column) 형태로 정리된 표(Table) 기반 데이터\n",
    "> - 정형 데이터 사용 알고리즘 : 선형 회귀 (Linear Regression), 로지스틱 회귀 (Logistic Regression), 의사결정트리 (Decision Tree)\n",
    "> - 비정형 데이터 : 텍스트, 이미지, 음성, 영상 등 규칙적인 구조가 없는 데이터\n",
    "> - 비정형 데이터 사용 알고리즘 : <br>\n",
    " -- RNN (Recurrent Neural Network) — 순서 있는 데이터 (텍스트, 시계열) <br>\n",
    " -- CNN (Convolutional Neural Network) — 공간 구조 있는 데이터 (이미지, 영상)  <br>\n",
    " -- LSTM (Long Short-Term Memory) — RNN의 발전형 (장기 기억 가능) // RNN의 기억력 문제를 해결한 고급 RNN 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f283c-08d9-4fb7-9dd5-bc0c55906d02",
   "metadata": {},
   "source": [
    "### 1. 랜덤 포레스트\n",
    ">- 결정 트리(Decision Tree)의 단점을 보완한 앙상블(Ensemble) 모델\n",
    ">- 결정 트리(Decision Tree)는 해석이 쉽지만, 데이터에 너무 민감해서 과적합(Overfitting) 되기 쉽습니다\n",
    ">- 여러 트리를 각각 다르게 학습시켜서, 그들의 평균(혹은 투표)을 취하면 → 과적합이 줄고 일반화 성능이 높아집니다\n",
    ">- 여러 개의 결정 트리(Decision Tree)를 무작위로 만들어, 그들의 예측을 투표(Voting) 나 평균(Averaging) 해서 결과를 내는 모델\n",
    "> - 여러 트리를 심어서(포레스트 = 숲), 다수결로 예측한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e1ad0-3b90-45dd-8ebb-4c2d8900ac38",
   "metadata": {},
   "source": [
    "#### **앙상블 모델**이란 여러 개의 머신러닝 모델을 조합하여, 하나의 예측 결과를 만드는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764e67a-4754-4779-9f00-51a48ae528c8",
   "metadata": {},
   "source": [
    "#### **부트스트랩 샘플**\n",
    ">  1,000개의 샘플이 들어있는 가방에서 100개의 샘플을 뽑는다면 먼저 1개를 뽑고, <br>\n",
    " 뽑았던 1개를 다시 가방에 넣는다. 이러식으로 계속해서 100개를 가방에서 뽑으면 중복된 샘플을 뽑을 수 있다. <br>\n",
    " 이러한 샘플을 **부트스트랩 샘플** 이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccba6d64-1a2f-494e-8420-ef0f64e84805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "\n",
    "# data = wine[['alcohol', 'sugar', 'pH']]\n",
    "# target = wine['class']\n",
    "\n",
    "data = wine[wine.columns[:-1]]   # 마지막 열 제외\n",
    "target = wine[wine.columns[-1]] \n",
    "# print(data.head())\n",
    "# print('*' * 50 )\n",
    "# print(target.head())\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265aa857-354b-4188-a441-814920cc67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 평균 점수: 0.9973541965122431\n",
      "검증 세트 평균 점수: 0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_jobs=-1: CPU 모든 코어를 사용해서 처리\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# 교차 검증(Cross Validation) 으로 모델 평가\n",
    "# train_input => 입력 데이터 (특성), train_target -> 타깃 데이터 (정답), return_train_score=True -> 훈련 세트의 점수도 함께 반환\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(\"훈련 세트 평균 점수:\", np.mean(scores['train_score']))\n",
    "print(\"검증 세트 평균 점수:\", np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e5b28c-78a3-4ed9-9183-71a4c20de4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 중요도(feature importance) 확인 :  [0.23167441 0.50039841 0.26792718]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)\n",
    "print(\"특성 중요도(feature importance) 확인 : \", rf.feature_importances_)\n",
    "\n",
    "# 'alcohol', 'sugar', 'pH' 순\n",
    "# [0.23167441 0.50039841 0.26792718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc188d6-1d1e-4e9e-b21e-edbe638aaa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 세트 점수: 0.8934000384837406\n"
     ]
    }
   ],
   "source": [
    "# oob_score=True -> 부트스트랩 샘플을 활용해 모델의 검증 점수를 자동으로 계산하도록 설정하는 것\n",
    "#                -> OOB(out-of-bag) 점수 계산 활성화\n",
    "# oob => 사용되지 않은 샘플(out-of-bag)\n",
    "# oob 샘플을 그 트리의 검증용으로 다시 사용하는 것\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(\"검증 세트 점수:\",rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed1f24-82da-49c5-bb1c-0f4b5bd73613",
   "metadata": {},
   "source": [
    "### 2. 엑스트라 트리\n",
    "> - 랜덤 포레스트(Random Forest) 와 비슷하지만 좀 더 “무작위성(randomness)”을 강하게 적용한 모델\n",
    "> - 랜덤 포레스트보다 더 랜덤하게 트리를 만드는 모델\n",
    "> - 여러 개의 무작위한 결정 트리(Decision Tree) 를 만들어 그 예측을 평균(회귀) 또는 투표(분류) 하는 앙상블 모델\n",
    "> - 부트스트랩을 사용하지 않음\n",
    "> - 랜덤 포레스트는 데이터를 랜덤하게 조금씩 썩어서 가장 잘 나누는 기준으로 트리를 만듦\n",
    "> - 데이터를 썩고(그대로 사용) , 대신 나누는 기준 자체를 랜덤하게 정함(약간 운에 좌우됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f21483-66e1-4d6b-9530-e9b4b6b6843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df40f93c-6946-46f1-b6ac-e2457e46d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20183568 0.52242907 0.27573525]\n"
     ]
    }
   ],
   "source": [
    "et.fit(train_input, train_target)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06143a-1752-4b5c-b0ed-da2e5600c266",
   "metadata": {},
   "source": [
    "### 3. 그레이디언트 부스팅\n",
    "> - **부스팅** 이란? 여러 개의 약한 모델(weak learner, 예: 얕은 결정트리)을 순차적으로 학습시키면서, 이전 모델의 오류를 보완하는 방식\n",
    "> - **부스팅** 이란? **정확도를 더 높이기 위해 만든 “업그레이드형 트리 모델”**\n",
    "> - 부스팅(Boosting) 방식 중에서도 오류를 보정할 때 **“기울기(gradient)”** 를 이용하는 방법이에요\n",
    "> - **“경사하강법(gradient descent)”** 처럼 이전 모델의 오차 방향을 따라 점점 개선해나간다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef00c941-b443-46f6-997f-151a86d0e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 트리 개수를 100\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e322bc5-e2bf-45a6-b683-7b1415e465b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464595437171814 0.8780082549788999\n"
     ]
    }
   ],
   "source": [
    "# 트리 개수를 100 → 500개로 늘림\n",
    "# 학습률을 0.1 → 0.2로 높임, 매 단계(트리)마다 이전 모델의 오류를 얼마나 크게 보정할지를 결정하는 비율\n",
    "# 오차의 10%만 반영 => 오차의 20% 반영\n",
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n",
    "                                random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c71a0f6-3b41-40a5-8d9d-171fb2335d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15882696 0.6799705  0.16120254]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466061a5-35fc-4328-8318-7429e99445b7",
   "metadata": {},
   "source": [
    "### 4. 히스토그램 기반 그레이디언트 부스팅\n",
    ">- 이전 모델이 틀린 부분(실수한 부분) 을 기억(=히스토리) 해 두고 그걸 다음 모델이 고쳐주는 방식이에요.\n",
    ">- 이전 모델이 틀린 부분(오류 기록)을 참고해서, 다음 모델이 점점 더 잘 맞추도록 고쳐 나가는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae1e6a3-b436-4296-bba4-55de26a2ccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0b1ea7-599b-4b50-b32b-7472ddf4637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ict\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] 지정된 파일을 찾을 수 없습니다\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\ict\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\ict\\anaconda3\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ict\\anaconda3\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ict\\anaconda3\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08876275 0.23438522 0.08027708]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "hgb.fit(train_input, train_target)\n",
    "result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2282d5c-bd7f-4a1d-b6be-10531d7760d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
